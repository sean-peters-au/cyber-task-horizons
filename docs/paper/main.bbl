\begin{thebibliography}{45}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Radford et~al.(2019)Radford, Wu, Child, Luan, Amodei, Sutskever, et~al.]{radford2019language}
Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever, et~al.
\newblock Language models are unsupervised multitask learners.
\newblock \emph{OpenAI blog}, 1\penalty0 (8):\penalty0 9, 2019.

\bibitem[Wijk et~al.(2024)Wijk, Lin, Becker, Jawhar, Parikh, Broadley, Chan, Chen, Clymer, Dhyani, et~al.]{wijk2024re}
Hjalmar Wijk, Tao Lin, Joel Becker, Sami Jawhar, Neev Parikh, Thomas Broadley, Lawrence Chan, Michael Chen, Josh Clymer, Jai Dhyani, et~al.
\newblock {RE}-{B}ench: Evaluating frontier {AI} {R\&D} capabilities of language model agents against human experts.
\newblock \emph{arXiv preprint arXiv:2411.15114}, 2024.

\bibitem[Phuong et~al.(2024)Phuong, Aitchison, Catt, Cogan, Kaskasoli, Krakovna, Lindner, Rahtz, Assael, Hodkinson, et~al.]{phuong2024evaluating}
Mary Phuong, Matthew Aitchison, Elliot Catt, Sarah Cogan, Alexandre Kaskasoli, Victoria Krakovna, David Lindner, Matthew Rahtz, Yannis Assael, Sarah Hodkinson, et~al.
\newblock Evaluating frontier models for dangerous capabilities.
\newblock \emph{arXiv preprint arXiv:2403.13793}, 2024.

\bibitem[Zellers et~al.(2019)Zellers, Holtzman, Bisk, Farhadi, and Choi]{zellers2019hellaswag}
Rowan Zellers, Ari Holtzman, Yonatan Bisk, Ali Farhadi, and Yejin Choi.
\newblock {HellaSwag}: Can a machine really finish your sentence?
\newblock In \emph{Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics}, pages 4791--4800, 2019.

\bibitem[Phan et~al.(2025)Phan, Gatti, Han, Li, Hu, Zhang, Shi, Choi, Agrawal, Chopra, et~al.]{phan2025humanity}
Long Phan, Alice Gatti, Ziwen Han, Nathaniel Li, Josephina Hu, Hugh Zhang, Sean Shi, Michael Choi, Anish Agrawal, Arnav Chopra, et~al.
\newblock Humanity's last exam.
\newblock \emph{arXiv preprint arXiv:2501.14249}, 2025.

\bibitem[Maslej et~al.(2024)Maslej, Fattorini, Perrault, Parli, Reuel, Brynjolfsson, Etchemendy, Ligett, Lyons, Manyika, Niebles, Shoham, Wald, and Clark]{maslej2024aiindexreport}
Nestor Maslej, Loredana Fattorini, Raymond Perrault, Vanessa Parli, Anka Reuel, Erik Brynjolfsson, John Etchemendy, Katrina Ligett, Terah Lyons, James Manyika, Juan~Carlos Niebles, Yoav Shoham, Russell Wald, and Jack Clark.
\newblock Artificial intelligence index report 2024, 2024.
\newblock URL \url{https://arxiv.org/abs/2405.19522}.

\bibitem[Chowdhury et~al.(2024)Chowdhury, Aung, Shern, Jaffe, Sherburn, Starace, Mays, Dias, Aljubeh, Glaese, Jimenez, Yang, Ho, Patwardhan, Liu, and Madry]{chowdhury2024SWEbench}
Neil Chowdhury, James Aung, Chan~Jun Shern, Oliver Jaffe, Dane Sherburn, Giulio Starace, Evan Mays, Rachel Dias, Marwan Aljubeh, Mia Glaese, Carlos~E. Jimenez, John Yang, Leyton Ho, Tejal Patwardhan, Kevin Liu, and Aleksander Madry.
\newblock Introducing {SWE}-{b}ench verified.
\newblock \url{https://openai.com/index/introducing-swe-bench-verified/}, 2024.
\newblock Accessed: 2025-02-26.

\bibitem[Rein et~al.(2025)Rein, Becker, Deng, Nix, Canal, O'Connell, Arnott, Bloom, Broadley, Garcia, Goodrich, Hasin, Jawhar, Kinniment, Kwa, Lajko, Rush, Sato, Von~Arx, West, Chan, and Barnes]{METR_HCAST}
David Rein, Joel Becker, Amy Deng, Seraphina Nix, Chris Canal, Daniel O'Connell, Pip Arnott, Ryan Bloom, Thomas Broadley, Katharyn Garcia, Brian Goodrich, Max Hasin, Sami Jawhar, Megan Kinniment, Thomas Kwa, Aron Lajko, Nate Rush, Lucas Jun~Koba Sato, Sydney Von~Arx, Ben West, Lawrence Chan, and Elizabeth Barnes.
\newblock {HCAST}: {H}uman-{C}alibrated {A}utonomy {S}oftware {T}asks.
\newblock Forthcoming, 2025.

\bibitem[Wang et~al.(2018)Wang, Singh, Michael, Hill, Levy, and Bowman]{wang2018glue}
Alex Wang, Amanpreet Singh, Julian Michael, Felix Hill, Omer Levy, and Samuel~R. Bowman.
\newblock {GLUE}: A multi-task benchmark and analysis platform for natural language understanding.
\newblock In \emph{International Conference on Learning Representations (ICLR)}, 2018.
\newblock URL \url{https://gluebenchmark.com/}.

\bibitem[Wang et~al.(2019)Wang, Pruksachatkun, Nangia, Singh, Michael, and Bowman]{wang2019superglue}
Alex Wang, Yada Pruksachatkun, Naman Nangia, Amanpreet Singh, Julian Michael, and Samuel~R. Bowman.
\newblock {SuperGLUE}: A stickier benchmark for general-purpose language understanding systems.
\newblock In \emph{Advances in Neural Information Processing Systems (NeurIPS) Workshop}, 2019.
\newblock URL \url{https://super.gluebenchmark.com/}.

\bibitem[Hendrycks et~al.(2020)Hendrycks, Burns, Basart, Zou, Mazeika, Song, and Steinhardt]{hendrycks2020measuring}
Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn Song, and Jacob Steinhardt.
\newblock Measuring massive multitask language understanding.
\newblock \emph{CoRR}, abs/2009.03300, 2020.
\newblock URL \url{https://arxiv.org/abs/2009.03300}.

\bibitem[Liu et~al.(2023)Liu, Yu, Zhang, Xu, Lei, Lai, Gu, Ding, Men, Yang, Zhang, Deng, Zeng, Du, Zhang, Shen, Zhang, Su, Sun, Huang, Dong, and Tang]{liu2023agentbench}
Xiao Liu, Hao Yu, Hanchen Zhang, Yifan Xu, Xuanyu Lei, Hanyu Lai, Yu~Gu, Hangliang Ding, Kaiwen Men, Kejuan Yang, Shudan Zhang, Xiang Deng, Aohan Zeng, Zhengxiao Du, Chenhui Zhang, Sheng Shen, Tianjun Zhang, Yu~Su, Huan Sun, Minlie Huang, Yuxiao Dong, and Jie Tang.
\newblock Agentbench: Evaluating llms as agents.
\newblock \emph{arXiv preprint arXiv:2308.03688}, 2023.
\newblock URL \url{https://arxiv.org/abs/2308.03688}.

\bibitem[Huang et~al.(2024)Huang, Vora, Liang, and Leskovec]{huang2024mlagentbench}
Qian Huang, Jian Vora, Percy Liang, and Jure Leskovec.
\newblock {MLAgentBench}: evaluating language agents on machine learning experimentation.
\newblock In \emph{Proceedings of the 41st International Conference on Machine Learning}, ICML'24. JMLR.org, 2024.

\bibitem[Qin et~al.(2023)Qin, Liang, Ye, Zhu, Yan, Lu, Lin, Cong, Tang, Qian, Zhao, Hong, Tian, Xie, Zhou, Gerstein, Li, Liu, and Sun]{qin2023toolllm}
Yujia Qin, Shihao Liang, Yining Ye, Kunlun Zhu, Lan Yan, Yaxi Lu, Yankai Lin, Xin Cong, Xiangru Tang, Bill Qian, Sihan Zhao, Lauren Hong, Runchu Tian, Ruobing Xie, Jie Zhou, Mark Gerstein, Dahai Li, Zhiyuan Liu, and Maosong Sun.
\newblock Toolllm: Facilitating large language models to master 16000+ real-world apis, 2023.
\newblock URL \url{https://arxiv.org/abs/2307.16789}.

\bibitem[Roberts et~al.(2025)Roberts, Taesiri, Sharma, Gupta, Roberts, Croitoru, Bogolin, Tang, Langer, Raina, Raina, Xiong, Udandarao, Lu, Chen, Purkis, Yan, Lin, Shin, Yang, Nguyen, Atkinson, Baranwal, Coca, Dang, Dziadzio, Kunz, Liang, Lo, Pulfer, Walton, Yang, Han, and Albanie]{roberts2025zerobench}
Jonathan Roberts, Mohammad~Reza Taesiri, Ansh Sharma, Akash Gupta, Samuel Roberts, Ioana Croitoru, Simion-Vlad Bogolin, Jialu Tang, Florian Langer, Vyas Raina, Vatsal Raina, Hanyi Xiong, Vishaal Udandarao, Jingyi Lu, Shiyang Chen, Sam Purkis, Tianshuo Yan, Wenye Lin, Gyungin Shin, Qiaochu Yang, Anh~Totti Nguyen, David~I. Atkinson, Aaditya Baranwal, Alexandru Coca, Mikah Dang, Sebastian Dziadzio, Jakob~D. Kunz, Kaiqu Liang, Alexander Lo, Brian Pulfer, Steven Walton, Charig Yang, Kai Han, and Samuel Albanie.
\newblock {ZeroBench}: An impossible visual benchmark for contemporary large multimodal models, 2025.
\newblock URL \url{https://arxiv.org/abs/2502.09696}.

\bibitem[Mialon et~al.(2024)Mialon, Fourrier, Wolf, LeCun, and Scialom]{mialon2024gaia}
Gr{\'e}goire Mialon, Cl{\'e}mentine Fourrier, Thomas Wolf, Yann LeCun, and Thomas Scialom.
\newblock {GAIA}: a benchmark for general {AI} assistants.
\newblock In \emph{The Twelfth International Conference on Learning Representations}, 2024.
\newblock URL \url{https://openreview.net/forum?id=fibxvahvs3}.

\bibitem[Srivastava et~al.(2022)]{srivastava2022beyond}
[Author] Srivastava et~al.
\newblock Beyond the imitation game: Quantifying and extrapolating the capabilities of language models.
\newblock \emph{arXiv preprint arXiv:2206.04615}, 2022.

\bibitem[Chen et~al.(2021)Chen, Tworek, Jun, Yuan, Ponde~de Oliveira~Pinto, Kaplan, Edwards, Burda, Joseph, Brockman, et~al.]{chen2021evaluating}
Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde~de Oliveira~Pinto, Jared Kaplan, Harri Edwards, Yuri Burda, Nicholas Joseph, Greg Brockman, et~al.
\newblock Evaluating large language models trained on code, 2021.
\newblock URL \url{https://arxiv.org/abs/2107.03374}.
\newblock arXiv preprint, arXiv:2107.03374.

\bibitem[Austin et~al.(2021)Austin, Odena, et~al.]{austin2021program}
Jeremy Austin, Augustus Odena, et~al.
\newblock Program synthesis with large language models, 2021.
\newblock URL \url{https://arxiv.org/abs/2108.07732}.
\newblock arXiv preprint, arXiv:2108.07732.

\bibitem[Jimenez et~al.(2024)Jimenez, Yang, Wettig, Yao, Pei, Press, and Narasimhan]{jimenez2024swebench}
Carlos~E Jimenez, John Yang, Alexander Wettig, Shunyu Yao, Kexin Pei, Ofir Press, and Karthik~R Narasimhan.
\newblock {SWE}-bench: Can language models resolve real-world github issues?
\newblock In \emph{The Twelfth International Conference on Learning Representations}, 2024.
\newblock URL \url{https://openreview.net/forum?id=VTF8yNQM66}.

\bibitem[Hendrycks et~al.(2021)Hendrycks, Basart, Kadavath, Mazeika, Arora, Guo, Burns, Puranik, He, Song, et~al.]{hendrycks2021measuring}
Dan Hendrycks, Steven Basart, Saurav Kadavath, Mantas Mazeika, Akul Arora, Ethan Guo, Collin Burns, Samir Puranik, Horace He, Dawn Song, et~al.
\newblock Measuring coding challenge competence with apps.
\newblock In \emph{Advances in Neural Information Processing Systems (NeurIPS) Datasets and Benchmarks Track}, 2021.
\newblock URL \url{https://arxiv.org/abs/2105.09938}.

\bibitem[Amodei and Hernandez(2018)]{amodei2018ai}
Dario Amodei and Danny Hernandez.
\newblock Ai and compute, 2018.
\newblock URL \url{https://openai.com/blog/ai-and-compute/}.
\newblock OpenAI blog post, May 16, 2018.

\bibitem[{Epoch AI}(2024)]{EpochNotableModels2024}
{Epoch AI}.
\newblock Data on notable {AI} models, 2024.
\newblock URL \url{https://epoch.ai/data/notable-ai-models}.
\newblock Accessed: 2025-03-04.

\bibitem[Sevilla et~al.(2022)Sevilla, Heim, Ho, Besiroglu, Hobbhahn, and Villalobos]{sevilla2022compute}
Jaime Sevilla, Lennart Heim, Anson Ho, Tamay Besiroglu, Marius Hobbhahn, and Pablo Villalobos.
\newblock Compute trends across three eras of machine learning.
\newblock In \emph{2022 International Joint Conference on Neural Networks (IJCNN)}, pages 1--8. IEEE, 2022.

\bibitem[Owen(2024)]{owen2024predictable}
David Owen.
\newblock How predictable is language model benchmark performance?, 2024.

\bibitem[Pimpale et~al.(2025)Pimpale, Højmark, Scheurer, and Hobbhahn]{pimpale2025forecastingfrontierlanguagemodel}
Govind Pimpale, Axel Højmark, Jérémy Scheurer, and Marius Hobbhahn.
\newblock Forecasting frontier language model agent capabilities, 2025.
\newblock URL \url{https://arxiv.org/abs/2502.15850}.

\bibitem[Murray et~al.(2025)Murray, Papadatos, Quarks, Gimenez, and Campos]{murray2025mapping}
Malcolm Murray, Henry Papadatos, Otter Quarks, Pierre-Fran{\c{c}}ois Gimenez, and Simeon Campos.
\newblock Mapping ai benchmark data to quantitative risk estimates through expert elicitation.
\newblock \emph{arXiv preprint arXiv:2503.04299}, 2025.

\bibitem[Zhang et~al.(2024)Zhang, Perry, Dulepet, Ji, Menders, Lin, Jones, Hussein, Liu, Jasper, et~al.]{zhang2024cybench}
Andy~K Zhang, Neil Perry, Riya Dulepet, Joey Ji, Celeste Menders, Justin~W Lin, Eliot Jones, Gashon Hussein, Samantha Liu, Donovan Jasper, et~al.
\newblock Cybench: A framework for evaluating cybersecurity capabilities and risks of language models.
\newblock \emph{arXiv preprint arXiv:2408.08926}, 2024.

\bibitem[Carlsmith(2020)]{carlsmith2020compute}
Joseph Carlsmith.
\newblock How much computational power does it take to match the human brain?, 2020.
\newblock URL \url{https://www.openphilanthropy.org/research/how-much-computational-power-does-it-take-to-match-the-human-brain/}.
\newblock Open Philanthropy report, August 14, 2020.

\bibitem[Cotra(2020)]{cotra2020forecasting}
Ajeya Cotra.
\newblock Draft report on ai timelines, 2020.
\newblock URL \url{https://www.alignmentforum.org/posts/KrJfoZzpSDpnrv9va/draft-report-on-ai-timelines}.
\newblock Draft report on AI timelines; technical report.

\bibitem[Ngo(2023)]{ngo2023tagi}
Richard Ngo.
\newblock Clarifying and predicting {AGI}.
\newblock \url{https://www.lesswrong.com/posts/BoA3agdkAzL6HQtQP/clarifying-and-predicting-agi}, 2023.
\newblock Accessed: 2024-03-21.

\bibitem[Baker(2001)]{baker2001basics}
Frank~B Baker.
\newblock \emph{The basics of item response theory}.
\newblock ERIC, 2001.

\bibitem[de~Ayala(2017)]{de2017handbook}
R.~J. de~Ayala.
\newblock \emph{Handbook of Item Response Theory: Models, Applications, and Issues}.
\newblock Guilford Press, 2017.

\bibitem[Martínez-Plumed et~al.(2019)Martínez-Plumed, Prudêncio, Martínez-Usó, and Hernández-Orallo]{martinezplumed201918item}
Fernando Martínez-Plumed, Ricardo~B.C. Prudêncio, Adolfo Martínez-Usó, and José Hernández-Orallo.
\newblock Item response theory in ai: Analysing machine learning classifiers at the instance level.
\newblock \emph{Artificial Intelligence}, 271:\penalty0 18--42, 2019.
\newblock ISSN 0004-3702.
\newblock \doi{https://doi.org/10.1016/j.artint.2018.09.004}.
\newblock URL \url{https://www.sciencedirect.com/science/article/pii/S0004370219300220}.

\bibitem[Song and Flach(2021)]{song2021efficient}
Hao Song and Peter Flach.
\newblock Efficient and robust model benchmarks with item response theory and adaptive testing.
\newblock \emph{International Journal of Interactive Multimedia and Artificial Intelligence}, 2021.

\bibitem[Paperno et~al.(2016)Paperno, Kruszewski, Lazaridou, Pham, Bernardi, Pezzelle, Baroni, Boleda, and Fern{\'a}ndez]{paperno2016lambada}
Denis Paperno, Germ{\'a}n Kruszewski, Angeliki Lazaridou, Ngoc-Quan Pham, Raffaella Bernardi, Sandro Pezzelle, Marco Baroni, Gemma Boleda, and Raquel Fern{\'a}ndez.
\newblock The {LAMBADA} dataset: Word prediction requiring a broad discourse context.
\newblock In \emph{Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)}, pages 1525--1534, 2016.

\bibitem[Cobbe et~al.(2021)Cobbe, Kosaraju, Bavarian, Chen, Jun, Kaiser, Plappert, Tworek, Hilton, Nakano, et~al.]{cobbe2021training}
Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser, Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano, et~al.
\newblock Training verifiers to solve math word problems.
\newblock \emph{arXiv preprint arXiv:2110.14168}, 2021.

\bibitem[OpenAI(2025)]{o3mini}
OpenAI.
\newblock Openai o3-mini.
\newblock \url{https://openai.com/index/openai-o3-mini}, 2025.
\newblock [Accessed 18-03-2025].

\bibitem[Zielinski(2019)]{zielinski_optimize_onboarding}
Dave Zielinski.
\newblock How to optimize onboarding, June 2019.
\newblock URL \url{https://www.shrm.org/topics-tools/news/hr-magazine/how-to-optimize-onboarding}.
\newblock Accessed on March 17, 2025.

\bibitem[Erdil and Besiroglu(2023)]{erdil2023algorithmicprogresscomputervision}
Ege Erdil and Tamay Besiroglu.
\newblock Algorithmic progress in computer vision, 2023.
\newblock URL \url{https://arxiv.org/abs/2212.05153}.

\bibitem[Ho et~al.(2024)Ho, Besiroglu, Erdil, Owen, Rahman, Guo, Atkinson, Thompson, and Sevilla]{ho2024algorithmicprogresslanguagemodels}
Anson Ho, Tamay Besiroglu, Ege Erdil, David Owen, Robi Rahman, Zifan~Carl Guo, David Atkinson, Neil Thompson, and Jaime Sevilla.
\newblock Algorithmic progress in language models, 2024.
\newblock URL \url{https://arxiv.org/abs/2403.05812}.

\bibitem[Jiang et~al.(2025)Jiang, Schmidt, Srikanth, Xu, Kaplan, Jacenko, and Wu]{jiang2025aide}
Zhengyao Jiang, Dominik Schmidt, Dhruv Srikanth, Dixing Xu, Ian Kaplan, Deniss Jacenko, and Yuxiang Wu.
\newblock {AIDE}: Ai-driven exploration in the space of code.
\newblock \emph{arXiv preprint arXiv:2502.13138}, 2025.

\bibitem[Xu et~al.(2024)Xu, Song, Li, Tang, Jain, Bao, Wang, Zhou, Guo, Cao, et~al.]{xu2024theagentcompany}
Frank~F Xu, Yufan Song, Boxuan Li, Yuxuan Tang, Kritanjali Jain, Mengxue Bao, Zora~Z Wang, Xuhui Zhou, Zhitong Guo, Murong Cao, et~al.
\newblock Theagentcompany: benchmarking llm agents on consequential real world tasks.
\newblock \emph{arXiv preprint arXiv:2412.14161}, 2024.

\bibitem[Yao et~al.(2023)Yao, Zhao, Yu, Du, Shafran, Narasimhan, and Cao]{yao2023reactsynergizingreasoningacting}
Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik Narasimhan, and Yuan Cao.
\newblock React: Synergizing reasoning and acting in language models, 2023.
\newblock URL \url{https://arxiv.org/abs/2210.03629}.

\bibitem[Roodman(2020)]{Roodman2020growthrate}
David~Malin Roodman.
\newblock On the probability distribution of long-term changes in the growth rate of the global economy: An outside view, 2020.
\newblock URL \url{https://api.semanticscholar.org/CorpusID:221641799}.

\end{thebibliography}

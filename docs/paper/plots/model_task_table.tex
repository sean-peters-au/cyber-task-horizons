\begin{table}[htbp]
\caption{Average Success Rate by Model and Task Source}
\label{tab:model_task_success}
\begin{tabular}{lrrr}
\toprule
task_source & HCAST & RE-Bench & SWAA \\
alias &  &  &  \\
\midrule
\textbf{Claude 3 Opus} & 0.253 & 0.000 & 0.985 \\
\textbf{Claude 3.5 Sonnet (New)} & 0.458 & 0.107 & 0.991 \\
\textbf{Claude 3.5 Sonnet (Old)} & 0.383 & 0.054 & 1.000 \\
\textbf{Claude 3.7 Sonnet} & 0.587 & 0.036 & 1.000 \\
\textbf{GPT-2} & 0.000 & 0.000 & 0.398 \\
\textbf{GPT-4 0314} & 0.232 & 0.000 & 0.985 \\
\textbf{GPT-4 1106} & 0.296 & 0.018 & 0.972 \\
\textbf{GPT-4 Turbo} & 0.228 & 0.000 & 1.000 \\
\textbf{GPT-4o} & 0.302 & 0.000 & 0.981 \\
\textbf{davinci-002 (GPT-3)} & 0.000 & 0.000 & 0.646 \\
\textbf{gpt-3.5-turbo-instruct} & 0.008 & 0.000 & 0.945 \\
\textbf{o1} & 0.537 & 0.071 & 0.996 \\
\textbf{o1-preview} & 0.438 & 0.020 & 1.000 \\
\bottomrule
\end{tabular}
\end{table}
